



# optimize for attention

## deepseek

[NativeSparseAttention](https://github.com/fla-org/native-sparse-attention)

[TransMLA](https://github.com/fxmeng/TransMLA)

[FlashMLA](https://github.com/deepseek-ai/FlashMLA)


