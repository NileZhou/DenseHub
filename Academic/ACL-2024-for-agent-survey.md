1. Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents链接：https://aclanthology.org/2024.acl-long.61.pdf 简介：这篇文章主要介绍了一种名为Intention-in-Interaction (IN3)的新颖基准，旨在通过明确的查询来检测用户的隐含意图。文章中使用IN3来训练Mistral-Interact，能够主动评估任务的模糊性，用于增强用户-代理交互中的隐含意图理解，并通过实验证明了其有效性。 

2. IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation链接：https://aclanthology.org/2024.acl-long.88.pdf 简介：这篇文章介绍了一个名为IBSEN的框架，该框架用于生成可控的、交互式的戏剧脚本。该框架由导演代理和演员代理组成，旨在通过协作来生成符合用户期望的戏剧情节。 

3. INCHARACTER: Evaluating Personality Fidelity in Role-Playing Agents through Psychological Interviews链接：https://aclanthology.org/2024.acl-long.102.pdf 简介：这篇文章介绍了一种名为INCHARACTER的方法，用于评估角色扮演代理（RPAs）的个性保真度。该方法通过使用心理量表进行心理测试来评估RPAs是否准确地再现了目标角色的个性。 

4. Rethinking Task-Oriented Dialogue Systems: From Complex Modularity to Zero-Shot Autonomous Agent链接：https://aclanthology.org/2024.acl-long.152.pdf 简介：这篇文章介绍了一种名为AutoTOD的新型任务导向对话系统，它旨在解决传统任务导向对话系统（TOD）的局限性。它通过一个简单的指令架构，包括任务和外部API的描述，使系统能够自主决定在每个对话回合中要做什么。 

5. AUTOACT: Automatic Agent Learning from Scratch for QA via Self-Planning链接：https://aclanthology.org/2024.acl-long.165.pdf 简介：这篇文章介绍了一个名为AUTOACT的自动代理学习框架，用于问答任务。该框架旨在解决现有语言代理系统面临的两个主要问题：对昂贵、不可复制的数据的依赖，以及将单个模型用于多个功能的挑战。 

6. TIMEARENA: Shaping Efficient Multitasking Language Agents in a Time-Aware Simulation链接：https://aclanthology.org/2024.acl-long.215.pdf 简介：这篇文章介绍了一种名为TIMEARENA的新型文本模拟环境，用于评估大型语言模型（LLMs）在多任务处理和时间规划方面的能力。 

7. MapCoder: Multi-Agent Code Generation for Competitive Problem Solving链接：https://aclanthology.org/2024.acl-long.269.pdf 简介：这篇文章介绍了一种名为MapCoder的多代理代码生成框架，用于解决竞争性编程问题。该框架由四个LLM agent组成，分别负责回忆相关示例、规划、代码生成和调试。这些agent通过模仿人类程序员在解决问题时的周期实现复杂代码生成。 

8. QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback-based Self-Correction链接：https://aclanthology.org/2024.acl-long.274.pdf 简介：这篇文章介绍了一种名为QueryAgent的可靠且高效的推理框架，该框架利用环境反馈进行自校正。该框架旨在解决在使用大型语言模型、进行语义解析时遇到的可靠性和效率问题。文章表明，通过结合环境反馈和自校正，可以显著提高KBQA任务的可靠性和效率，特别是在处理复杂问题时。 

9. Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization链接：https://aclanthology.org/2024.acl-long.292.pdf 简介：这篇文章主要介绍了一种名为Agent-Pro的LLM-based agent框架，该框架具有策略级别的反思和优化能力，能够通过交互经验学习大量专业知识，并逐步提升其行为策略。 

10. Experiential Co-Learning of Software-Developing Agents链接：https://aclanthology.org/2024.acl-long.305.pdf 简介：这篇文章介绍了一种新颖的LLM-based agent学习框架，主要包括：Co-Tracking（共同跟踪）、Co-Memorizing（共同记忆）、Co-Reasoning（共同推理）三个核心模块。通过这些模块，代理能够从过去的任务中学习经验，从而提高软件开发任务的执行效率。 

11. Speaker Verification in Agent-generated Conversations链接：https://aclanthology.org/2024.acl-long.307.pdf 简介：这篇文章介绍了一个新颖的评估挑战：在代理生成的对话中进行说话人验证。文章的主要目的是评估角色扮演模型是否能够准确地模拟不同说话者的特征和风格。文章发现当前的角色扮演模型在模拟说话者方面存在困难，主要原因是它们具有固有的语言特征。 

12. Benchmarking Data Science Agents链接：https://aclanthology.org/2024.acl-long.308.pdf 简介：这篇文章介绍了一种名为DSEval的新型评估范式，用于评估数据科学代理（Data Science Agents）的性能。DSEval旨在通过提供一系列全面的基准测试，涵盖数据科学生命周期的各个方面，来评估代理在数据分析和处理方面的能力。 

13. Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?链接：https://aclanthology.org/2024.acl-long.331.pdf 简介：这篇文章对当前关于多代理讨论可以提高LLMs推理能力的观点进行了质疑，并提供了新的见解。文章发现，在有示范的情况下，单个LLM可以达到与多代理讨论相当的性能；在没有示范的情况下，多代理讨论可以提高LLMs的推理能力。此外，文章还分析了多代理讨论中常见的错误类型，包括判断错误和错误答案传播。 

14. Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents链接：https://aclanthology.org/2024.acl-long.409.pdf 简介：这篇文章介绍了一种名为“探索性轨迹优化”（ETO）的学习方法，用于增强大型语言模型（LLM）代理的性能。与之前的研究不同，ETO不仅依赖于成功的专家轨迹，还允许代理从其探索失败中学习。 

15. Enhancing Dialogue State Tracking Models through LLM-backed User-Agents Simulation链接：https://aclanthology.org/2024.acl-long.473.pdf 简介：这篇文章介绍了一种名为LLM-backed User-Agents Simulation (LUAS)的算法，用于增强对话状态跟踪（DST）模型。LUAS算法利用大型语言模型如GPT-4，来模拟用户和代理之间的对话，并生成带有DST标签的对话数据。然后，使用LLaMA 2对生成的数据和真实数据进行两阶段微调，以进行DST预测。 

16. On the Multi-turn Instruction Following for Conversational Web Agents链接：https://aclanthology.org/2024.acl-long.477.pdf 简介：这篇文章提出了一种名为Self-MAP的框架，用于解决多轮对话中的指令遵循问题，特别是针对会话式Web导航任务。该框架结合了记忆增强的规划和自我反思，以解决该任务中的挑战。实验结果表明，Self-MAP框架在解决该任务方面比其他基线方法更有效。 

17. Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents链接：https://aclanthology.org/2024.acl-long.478.pdf 简介：这篇文章介绍了一种名为Mobile-Bench的新型评估基准，用于评估基于大型语言模型的移动代理的性能。Mobile-Bench旨在解决当前LLM-based移动代理评估中存在的三个主要挑战，包括：UI操作的低效性、单一应用的局限性、评估指标不足。 

18. SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents链接：https://aclanthology.org/2024.acl-long.505.pdf 简介：这篇文章提出了一种名为SeeClick的新型视觉GUI代理，SeeClick仅依靠屏幕截图来自动化数字设备上的复杂任务，从而解决了传统GUI代理在与环境交互时面临的问题。 

19. BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents链接：https://aclanthology.org/2024.acl-long.530.pdf 简介：这篇文章提出了一种名为BadAgent的新型后门攻击方法，该方法可以嵌入到基于LLMs的智能代理中。通过在训练数据中添加恶意触发和恶意操作，BadAgent攻击方法可以在智能代理上实现高成功率的后门攻击。实验结果表明，BadAgent攻击方法对数据防御方法具有很高的鲁棒性。 

20. CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation链接：https://aclanthology.org/2024.acl-long.638.pdf 简介：这篇文章提出了一种名为CharacterEval的中文角色扮演对话代理评估基准，用于评估角色扮演对话代理的能力。该基准包括一个精心构建的、高质量的中文角色扮演对话数据集，以及一个多维度的评估方法。文章还开发了一个名为CharacterRM的角色扮演奖励模型，用于评估角色扮演对话代理的主观指标。 

21. Agent LUMOS: Unified and Modular Training for Open-Source Language Agents链接：https://aclanthology.org/2024.acl-long.670.pdf 简介：这篇文章主要介绍了一个名为LUMOS的开源语言代理框架，用于解决复杂交互任务。该框架具有学习性、统一性、模块化和开放性等特点。通过大规模的、统一的、高质量的训练注释和广泛的实验，文章证明了LUMOS在多个任务上的出色性能和泛化能力。 

22. SOTOPIA-π: Interactive Learning of Socially Intelligent Language Agents链接：https://aclanthology.org/2024.acl-long.698.pdf 简介：这篇文章主要介绍了一种名为SOTOPIA-π的交互式学习方法，用于提高语言代理的社交智能。该方法通过利用行为克隆和自我强化训练，基于过滤后的社交互动数据，根据大型语言模型（LLM）的评分，来改进语言代理的社交智能。 

23. LLMARENA: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments链接：https://aclanthology.org/2024.acl-long.705.pdf 简介：这篇文章主要介绍了一种名为LLMARENA的新型评估框架，用于评估大型语言模型在动态多代理环境中的多样化能力。该框架包括七个不同的游戏环境，旨在评估LLMs在空间推理、战略规划、数值推理、风险评估、沟通、对手建模和团队合作等方面的能力。 

24. CODEAGENT: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges链接：https://aclanthology.org/2024.acl-long.737.pdf 简介：这篇文章主要介绍了一种名为CODEAGENT的新型LLM-based代理框架，用于增强代码生成任务的性能。该框架通过整合五个编程工具和四个代理策略，帮助LLMs更有效地完成代码生成任务。实验结果表明，CODEAGENT在两个不同的代码生成任务上都取得了显著的性能提升，尤其是在基于仓库的代码生成任务上。 

25. Evaluating Very Long-Term Conversational Memory of LLM Agents链接：https://aclanthology.org/2024.acl-long.747.pdf 简介：这篇文章主要介绍了一种名为LOCOMO的新型数据集，用于评估大型语言模型（LLMs）在非常长期限对话中的记忆能力。该数据集包括10个非常长期限对话，每个对话包含600个回合和16K个标记，分布在最多32个会话中。文章还介绍了一种用于生成LOCOMO数据集的生成管道，并提出了一种用于评估LLMs在LOCOMO数据集上的记忆能力的评估框架。实验结果表明，LLMs在理解和生成非常长期限对话方面存在挑战，特别是对于时间推理和因果理解。 

26. PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents链接：https://aclanthology.org/2024.acl-long.779.pdf 简介：这篇文章介绍了一种名为PsychoGAT（Psychological Game AgenTs）的新颖心理测量范式，该范式为心理测量领域提供了一种创新的方法，通过将LLM代理应用于互动小说游戏中，实现了心理评估的通用游戏化，从而提高了参与者的参与度和评估的准确性。 

27. Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View链接：https://aclanthology.org/2024.acl-long.782.pdf 简介：这篇文章主要研究了大型语言模型（LLMs）在多代理社会中的合作机制。通过构建一个多代理社会模拟框架，文章研究了不同特质和思考模式下的LLM代理之间的合作。实验结果表明，某些合作策略比之前的顶级方法更有效，并且LLM代理表现出类似于人类的社会行为。此外，文章还将社会心理学的见解融入到LLM代理的合作中，以更好地理解他们的社会行为。 

28. Talk With Human-like Agents: Empathetic Dialogue Through Perceptible Acoustic Reception and Reaction链接：https://aclanthology.org/2024.acl-long.801.pdf 简介：这篇文章主要介绍了一种名为PerceptiveAgent的新型多模态对话系统，旨在通过整合语音模态感知来增强对话系统的同理心。文章指出，当前的多模态对话系统通常忽视了语音中的声学信息，这对于理解人类沟通的细微差别至关重要。为了解决这个问题，文章提出了一种名为"Speech Captioner"的模型，该模型能够感知语音中的声学信息，并将其转换为文本描述。此外，文章还引入了一个名为"MSMA-Synthesizer"的模型，该模型能够根据文本描述和情感标签生成具有同理心的语音响应。 

29. ChatDev: Communicative Agents for Software Development链接：https://aclanthology.org/2024.acl-long.810.pdf 简介：这篇文章主要介绍了一种名为ChatDev的新型软件开发框架，该框架通过使用多个LLMs驱动的软件代理，实现了高效的软件开发。该框架在设计、编码和测试阶段都表现出色，并且具有广泛的应用潜力。然而，文章也指出了ChatDev框架的一些局限性，如需要详细的软件需求描述和较高的计算资源要求。 

30. PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety链接：https://aclanthology.org/2024.acl-long.812.pdf 简介：这篇文章主要介绍了一种名为PsySafe的新型多代理系统安全框架，该框架基于心理学的方法，旨在评估、攻击和防御多代理系统的安全问题。文章首先介绍了PsySafe框架的背景和动机，然后详细描述了该框架的攻击方法、评估方法和防御方法。最后，文章通过广泛的实验验证了PsySafe框架的有效性，并得出结论认为该框架是一种有前途的多代理系统安全框架。 

31. EconAgent: Large Language Model-Empowered Agents for Simulating Macroeconomic Activities链接：https://aclanthology.org/2024.acl-long.829.pdf 简介：这篇文章主要介绍了一种名为EconAgent的新型智能代理，用于模拟宏观经济活动。该代理基于LLM，具有感知、记忆和行动三个模块，可以模拟个体行为。文章在多个宏观经济场景下进行了广泛的实验，结果表明EconAgent代理在模拟宏观经济活动中表现出色。 

32. AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents链接：https://aclanthology.org/2024.acl-long.850.pdf 简介：这篇文章主要介绍了一种名为AppWorld的新型框架，用于评估和推动交互式编码代理的发展。该框架包括AppWorld Engine和AppWorld Benchmark两个部分，分别用于模拟真实的数字活动和评估交互式编码代理的能力。 

33. Soft Self-Consistency Improves Language Model Agents链接：https://aclanthology.org/2024.acl-short.28.pdf 简介：这篇文章主要介绍了一种名为Soft Self-Consistency (SOFT-SC)的改进方法，用于提高大型语言模型（LLMs）在生成多个答案并选择最佳答案时的性能。该方法使用连续的分数来选择最佳答案，而不是使用多数票。实验结果表明，SOFT-SC在三个不同的交互式任务上都取得了显著的性能提升。 

34. AGR: Reinforced Causal Agent-Guided Self-explaining Rationalization链接：https://aclanthology.org/2024.acl-short.47.pdf 简介：这篇文章主要介绍了一种名为AGR的新型理性化方法，用于改进神经网络的可解释性。该方法通过引入一个强化因果代理来指导模型在训练过程中的优化方向，从而避免了模型在训练过程中的学习偏差。